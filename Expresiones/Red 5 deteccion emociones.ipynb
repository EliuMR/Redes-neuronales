{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXYlfvJVmJf3"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile,isdir, join\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras import layers, models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D, Dropout,Activation,MaxPooling2D,Flatten\n",
    "from keras.optimizers import RMSprop \n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1477,
     "status": "ok",
     "timestamp": 1627349627322,
     "user": {
      "displayName": "Hiesker Tronco",
      "photoUrl": "",
      "userId": "15754113249199284305"
     },
     "user_tz": 300
    },
    "id": "aQzRy5nYcRmO",
    "outputId": "a19e0ed7-a648-4575-99ac-05144880a7b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n",
      "Found 28273 images belonging to 6 classes.\n",
      "Found 7067 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "#Autor:Eliú Moreno Ramírez\n",
    "#Fecha: Mayo 2021\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile,isdir, join\n",
    "import numpy\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras import layers, models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D, Dropout,Activation,MaxPooling2D,Flatten\n",
    "from keras.optimizers import RMSprop \n",
    "\n",
    "ih, iw = 48, 48 #tamano de la imagen\n",
    "input_shape = (ih, iw, 1) #forma de la imagen: alto ancho y numero de canales\n",
    "\n",
    "#train_dir = 'data/minitrain' #directorio de entrenamiento\n",
    "#test_dir = 'data/minitest' #directorio de prueba\n",
    "train_dir = '/content/drive/MyDrive/archive.zip (Unzipped Files)/Expresiones/Exp1/Training/Training' #directorio de entrenamiento\n",
    "test_dir = '/content/drive/MyDrive/archive.zip (Unzipped Files)/Expresiones/Exp1/Testing/Testing' #directorio de prueba\n",
    "\n",
    "\n",
    "num_class = 6 #cuantas clases \n",
    "epochs = 15 #cuantas veces entrenar. En cada epoch hace una mejora en los parametros\n",
    "\n",
    "batch_size = 25 #batch para hacer cada entrenamiento. Lee 50 'batch_size' imagenes antes de actualizar los parametros. Las carga a memoria\n",
    "num_train = 7067 #numero de imagenes en train\n",
    "num_test = 28273 #numero de imagenes en test\n",
    "\n",
    "\n",
    "epoch_steps = num_train // batch_size \n",
    "test_steps = num_test // batch_size\n",
    "print(test_steps)\n",
    "\n",
    "gentrain = ImageDataGenerator(rescale=1. / 255.) #indica que reescale cada canal con valor entre 0 y 1.\n",
    "\n",
    "\n",
    "train = gentrain.flow_from_directory(train_dir,    \n",
    "                batch_size=batch_size,    \n",
    "                target_size=(iw, ih),\n",
    "                color_mode='grayscale',\n",
    "                class_mode='categorical')\n",
    "\n",
    "gentest = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test = gentest.flow_from_directory(test_dir,    \n",
    "                batch_size=batch_size,    \n",
    "                target_size=(iw, ih),\n",
    "                color_mode='grayscale',\n",
    "                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "-EewmzcKkoZf",
    "outputId": "a03310f9-1805-4fda-82fa-2ad5fa4aac80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1130/1130 [==============================] - 8305s 7s/step - loss: 1.9106 - accuracy: 0.2224 - val_loss: 1.7432 - val_accuracy: 0.2511\n",
      "Epoch 2/100\n",
      "1130/1130 [==============================] - 313s 277ms/step - loss: 1.7264 - accuracy: 0.2658 - val_loss: 1.8305 - val_accuracy: 0.2567\n",
      "Epoch 3/100\n",
      "1130/1130 [==============================] - 314s 277ms/step - loss: 1.6156 - accuracy: 0.3239 - val_loss: 1.5341 - val_accuracy: 0.3874\n",
      "Epoch 4/100\n",
      "1130/1130 [==============================] - 311s 275ms/step - loss: 1.5093 - accuracy: 0.3887 - val_loss: 1.3928 - val_accuracy: 0.4521\n",
      "Epoch 5/100\n",
      "1130/1130 [==============================] - 309s 273ms/step - loss: 1.4326 - accuracy: 0.4254 - val_loss: 1.3832 - val_accuracy: 0.4505\n",
      "Epoch 6/100\n",
      "1130/1130 [==============================] - 311s 275ms/step - loss: 1.3748 - accuracy: 0.4522 - val_loss: 1.2513 - val_accuracy: 0.4974\n",
      "Epoch 7/100\n",
      "1130/1130 [==============================] - 309s 273ms/step - loss: 1.3530 - accuracy: 0.4668 - val_loss: 1.2336 - val_accuracy: 0.5081\n",
      "Epoch 8/100\n",
      "1130/1130 [==============================] - 310s 275ms/step - loss: 1.3121 - accuracy: 0.4827 - val_loss: 1.2871 - val_accuracy: 0.4878\n",
      "Epoch 9/100\n",
      "1130/1130 [==============================] - 309s 274ms/step - loss: 1.2981 - accuracy: 0.4945 - val_loss: 1.2469 - val_accuracy: 0.5078\n",
      "Epoch 10/100\n",
      "1130/1130 [==============================] - 309s 274ms/step - loss: 1.2837 - accuracy: 0.4977 - val_loss: 1.2861 - val_accuracy: 0.4723\n",
      "Epoch 11/100\n",
      "1130/1130 [==============================] - 308s 273ms/step - loss: 1.2624 - accuracy: 0.5082 - val_loss: 1.2520 - val_accuracy: 0.4746\n",
      "Epoch 12/100\n",
      "1130/1130 [==============================] - 309s 273ms/step - loss: 1.2608 - accuracy: 0.5093 - val_loss: 1.3561 - val_accuracy: 0.4211\n",
      "Epoch 13/100\n",
      "1130/1130 [==============================] - 307s 272ms/step - loss: 1.2444 - accuracy: 0.5190 - val_loss: 1.1908 - val_accuracy: 0.5070\n",
      "Epoch 14/100\n",
      "1130/1130 [==============================] - 309s 274ms/step - loss: 1.2171 - accuracy: 0.5306 - val_loss: 1.2291 - val_accuracy: 0.5196\n",
      "Epoch 15/100\n",
      "1130/1130 [==============================] - 306s 271ms/step - loss: 1.2179 - accuracy: 0.5296 - val_loss: 1.1270 - val_accuracy: 0.5530\n",
      "Epoch 16/100\n",
      "1130/1130 [==============================] - 301s 267ms/step - loss: 1.1957 - accuracy: 0.5400 - val_loss: 1.1846 - val_accuracy: 0.5268\n",
      "Epoch 17/100\n",
      "1130/1130 [==============================] - 313s 277ms/step - loss: 1.1884 - accuracy: 0.5412 - val_loss: 1.1509 - val_accuracy: 0.5374\n",
      "Epoch 18/100\n",
      "1130/1130 [==============================] - 318s 282ms/step - loss: 1.1838 - accuracy: 0.5484 - val_loss: 1.1850 - val_accuracy: 0.5203\n",
      "Epoch 19/100\n",
      "1130/1130 [==============================] - 309s 273ms/step - loss: 1.1704 - accuracy: 0.5535 - val_loss: 1.1115 - val_accuracy: 0.5614\n",
      "Epoch 20/100\n",
      "1130/1130 [==============================] - 301s 266ms/step - loss: 1.1838 - accuracy: 0.5473 - val_loss: 1.2112 - val_accuracy: 0.5313\n",
      "Epoch 21/100\n",
      "1130/1130 [==============================] - 301s 267ms/step - loss: 1.1639 - accuracy: 0.5603 - val_loss: 1.4180 - val_accuracy: 0.4318\n",
      "Epoch 22/100\n",
      "1130/1130 [==============================] - 302s 268ms/step - loss: 1.1502 - accuracy: 0.5584 - val_loss: 1.0887 - val_accuracy: 0.5721\n",
      "Epoch 23/100\n",
      "1130/1130 [==============================] - 302s 267ms/step - loss: 1.1488 - accuracy: 0.5614 - val_loss: 1.0838 - val_accuracy: 0.5738\n",
      "Epoch 24/100\n",
      "1130/1130 [==============================] - 303s 268ms/step - loss: 1.1391 - accuracy: 0.5650 - val_loss: 1.0833 - val_accuracy: 0.5718\n",
      "Epoch 25/100\n",
      "1130/1130 [==============================] - 301s 266ms/step - loss: 1.1292 - accuracy: 0.5691 - val_loss: 1.1533 - val_accuracy: 0.5488\n",
      "Epoch 26/100\n",
      "1123/1130 [============================>.] - ETA: 1s - loss: 1.1305 - accuracy: 0.5661"
     ]
    }
   ],
   "source": [
    "#CREAMOS LAS ARQUITECTORA DEL MODELO\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (4, 4), input_shape=(ih, iw,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(36, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "         \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(60))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_class))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "covid_train=model.fit_generator(    \n",
    "                train,    \n",
    "                steps_per_epoch=epoch_steps,    \n",
    "                epochs=epochs,\n",
    "                validation_data=test,    \n",
    "                validation_steps=test_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjhbJAoOkx4I"
   },
   "outputs": [],
   "source": [
    "model.save('cvsd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vu6RDaYhzLnq"
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# serializar el modelo a JSON\n",
    "model_json = expresion_model.to_json()\n",
    "with open(\"modelexpresiones.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serializar los pesos a HDF5\n",
    "expresion_model.save_weights(\"pesosexpresione.h5\")\n",
    "print(\"Modelo Guardado!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN4df0n1b764yf8voqQLEY6",
   "mount_file_id": "1VsCqkcY5Edkpi9Coi2la3GQyJxdJIHAj",
   "name": "Delfin.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
